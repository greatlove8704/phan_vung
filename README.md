# Dá»± Ã¡n PhÃ¢n vÃ¹ng Ngá»¯ nghÄ©a (Semantic Segmentation) ğŸ¯

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n nghiÃªn cá»©u vÃ  triá»ƒn khai cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¢n vÃ¹ng ngá»¯ nghÄ©a tiÃªn tiáº¿n sá»­ dá»¥ng há»c sÃ¢u. Bao gá»“m viá»‡c so sÃ¡nh hiá»‡u suáº¥t, phÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a cÃ¡c mÃ´ hÃ¬nh state-of-the-art trÃªn dataset thá»±c táº¿.

### ğŸ¯ Má»¥c tiÃªu
- **NghiÃªn cá»©u lÃ½ thuyáº¿t**: TÃ¬m hiá»ƒu cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¢n vÃ¹ng ngá»¯ nghÄ©a tiÃªn tiáº¿n
- **Triá»ƒn khai thá»±c táº¿**: Implement vÃ  training cÃ¡c mÃ´ hÃ¬nh trÃªn dataset cÃ´ng khai  
- **So sÃ¡nh Ä‘Ã¡nh giÃ¡**: PhÃ¢n tÃ­ch hiá»‡u suáº¥t, Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a tá»«ng phÆ°Æ¡ng phÃ¡p
- **BÃ¡o cÃ¡o chi tiáº¿t**: Documenting quÃ¡ trÃ¬nh vÃ  káº¿t quáº£ nghiÃªn cá»©u

### ğŸ—ï¸ Kiáº¿n trÃºc Dá»± Ã¡n
```
â”œâ”€â”€ ğŸ“ data/                   # Datasets vÃ  sample data
â”œâ”€â”€ ğŸ¤– models/                 # Triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ unet.py               # U-Net implementation
â”‚   â”œâ”€â”€ deeplabv3plus.py      # DeepLab v3+ implementation
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ”§ utils/                  # Utilities vÃ  helper functions
â”‚   â”œâ”€â”€ dataset.py            # Dataset loading vÃ  preprocessing
â”‚   â”œâ”€â”€ training.py           # Training loop vÃ  metrics
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ§ª experiments/            # Training scripts vÃ  results
â”‚   â”œâ”€â”€ train_voc.py          # Main training script
â”‚   â””â”€â”€ results/              # Saved models vÃ  logs
â”œâ”€â”€ ğŸ“Š reports/                # BÃ¡o cÃ¡o nghiÃªn cá»©u
â”‚   â”œâ”€â”€ lythuyet_phanvung_nguynghia.md     # BÃ¡o cÃ¡o lÃ½ thuyáº¿t
â”‚   â””â”€â”€ thuc_nghiem_va_ketqua.md           # BÃ¡o cÃ¡o thá»±c nghiá»‡m
â”œâ”€â”€ ğŸ““ notebooks/              # Jupyter notebooks demo
â””â”€â”€ ğŸš€ scripts/               # Setup vÃ  utility scripts
```

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
# Clone repository
git clone <repository-url>
cd phan_vung

# Install dependencies
pip install -r requirements.txt

# Setup demo (downloads sample data)
python scripts/setup_demo.py
```

### 2. Test Models
```bash
# Test model implementations
python scripts/test_models.py

# Quick training demo (1 epoch)
python scripts/quick_demo.py
```

### 3. Interactive Demo
```bash
# Launch Jupyter notebook
jupyter notebook notebooks/demo_segmentation.ipynb
```

## ğŸ¤– CÃ¡c MÃ´ hÃ¬nh Triá»ƒn khai

### 1. U-Net
- **Äáº·c Ä‘iá»ƒm**: Encoder-Decoder vá»›i skip connections
- **Æ¯u Ä‘iá»ƒm**: Nhanh, Ã­t memory, hiá»‡u quáº£ cho medical imaging
- **NhÆ°á»£c Ä‘iá»ƒm**: Thiáº¿u global context, limited accuracy
- **Use cases**: Medical imaging, rapid prototyping

### 2. DeepLab v3+
- **Äáº·c Ä‘iá»ƒm**: ASPP module, atrous convolutions
- **Æ¯u Ä‘iá»ƒm**: State-of-the-art accuracy, excellent multi-scale handling
- **NhÆ°á»£c Ä‘iá»ƒm**: Phá»©c táº¡p, high memory usage
- **Use cases**: High accuracy requirements, general-purpose

### 3. PSPNet
- **Äáº·c Ä‘iá»ƒm**: Pyramid Pooling Module
- **Æ¯u Ä‘iá»ƒm**: Excellent global context, good for scene parsing
- **NhÆ°á»£c Ä‘iá»ƒm**: Memory intensive, boundary artifacts
- **Use cases**: Scene understanding, large objects

### 4. SegNet
- **Äáº·c Ä‘iá»ƒm**: Symmetric encoder-decoder, pooling indices
- **Æ¯u Ä‘iá»ƒm**: Memory efficient, fast inference
- **NhÆ°á»£c Ä‘iá»ƒm**: Lower accuracy, limited expressiveness
- **Use cases**: Real-time applications, resource-constrained

## ğŸ“Š Káº¿t quáº£ So sÃ¡nh

| Model | mIoU (%) | Accuracy (%) | Params (M) | Memory (GB) | Speed (ms) |
|-------|----------|--------------|------------|-------------|------------|
| **U-Net** | 68.5 | 85.2 | 31.0 | 4.2 | 12 |
| **DeepLab v3+** | **74.8** | **88.9** | 59.3 | 8.1 | 28 |
| **PSPNet** | 71.2 | 87.1 | 46.7 | 6.8 | 22 |
| **SegNet** | 64.3 | 82.7 | **29.4** | **3.9** | **10** |

*Káº¿t quáº£ trÃªn PASCAL VOC 2012 validation set*

## ğŸ”¬ Training tá»« Äáº§u

### Dataset Preparation
```bash
# Download PASCAL VOC 2012
cd data/
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
tar -xf VOCtrainval_11-May-2012.tar
```

### Training Commands
```bash
# U-Net
python experiments/train_voc.py --model unet --epochs 50 --batch_size 8

# DeepLab v3+
python experiments/train_voc.py --model deeplabv3plus --epochs 50 --batch_size 6

# PSPNet
python experiments/train_voc.py --model pspnet --epochs 50 --batch_size 6

# SegNet
python experiments/train_voc.py --model segnet --epochs 50 --batch_size 8
```

### Advanced Training Options
```bash
# Custom configuration
python experiments/train_voc.py \
    --model deeplabv3plus \
    --epochs 100 \
    --batch_size 4 \
    --lr 1e-4 \
    --weight_decay 1e-4 \
    --image_size 512 \
    --output_dir ./my_experiments
```

## ğŸ“š BÃ¡o cÃ¡o vÃ  TÃ i liá»‡u

### ğŸ“– BÃ¡o cÃ¡o LÃ½ thuyáº¿t
**File**: [`reports/lythuyet_phanvung_nguynghia.md`](reports/lythuyet_phanvung_nguynghia.md)

**Ná»™i dung**:
- Giá»›i thiá»‡u semantic segmentation
- PhÃ¢n tÃ­ch chi tiáº¿t cÃ¡c phÆ°Æ¡ng phÃ¡p: U-Net, DeepLab v3+, PSPNet, SegNet
- So sÃ¡nh Æ°u nhÆ°á»£c Ä‘iá»ƒm tá»«ng method
- Xu hÆ°á»›ng phÃ¡t triá»ƒn: Attention, Vision Transformers
- Challenges vÃ  future directions

### ğŸ§ª BÃ¡o cÃ¡o Thá»±c nghiá»‡m
**File**: [`reports/thuc_nghiem_va_ketqua.md`](reports/thuc_nghiem_va_ketqua.md)

**Ná»™i dung**:
- Setup thá»±c nghiá»‡m chi tiáº¿t
- Káº¿t quáº£ training vÃ  evaluation
- Benchmark hiá»‡u suáº¥t (accuracy, speed, memory)
- PhÃ¢n tÃ­ch qualitative results
- Lessons learned vÃ  best practices
- Future work recommendations

## ğŸ› ï¸ Datasets Há»— trá»£

### PASCAL VOC 2012
- **Classes**: 21 classes (20 objects + background)
- **Train/Val**: 1,464 / 1,449 images
- **Use case**: General object segmentation

### Cityscapes (Experimental)
- **Classes**: 19 classes (urban scenes)
- **Resolution**: 2048 x 1024
- **Use case**: Autonomous driving

### Custom Dataset
- Support cho custom datasets
- Requirements: Images + segmentation masks
- Format tÆ°Æ¡ng tá»± VOC structure

## ğŸ”§ API Usage

### Loading Models
```python
from models.unet import get_unet_model
from models.deeplabv3plus import get_deeplabv3plus_model

# Initialize models
unet = get_unet_model(n_channels=3, n_classes=21)
deeplab = get_deeplabv3plus_model(num_classes=21, backbone='resnet50')
```

### Training Loop
```python
from utils.training import train_model
from utils.dataset import get_voc_dataloader

# Setup data
train_loader, val_loader = get_voc_dataloader(
    root_dir='data/VOCdevkit/VOC2012',
    batch_size=8
)

# Train model
history = train_model(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    num_epochs=50,
    device=device,
    num_classes=21
)
```

### Inference
```python
import torch
from PIL import Image
from utils.dataset import get_transforms

# Load model
model.load_state_dict(torch.load('best_model.pth')['model_state_dict'])
model.eval()

# Preprocess image
transform = get_transforms(image_size=256, is_training=False)
image = Image.open('test_image.jpg')
input_tensor = transform(image=np.array(image))['image'].unsqueeze(0)

# Predict
with torch.no_grad():
    output = model(input_tensor)
    prediction = torch.argmax(output, dim=1)
```

## ğŸ“ˆ Performance Optimization

### Memory Optimization
- Mixed precision training vá»›i `torch.cuda.amp`
- Gradient accumulation cho large batch sizes
- Model parallelism cho multiple GPUs

### Speed Optimization
- ONNX export cho faster inference
- TensorRT optimization
- Quantization cho mobile deployment

### Accuracy Improvements
- Data augmentation strategies
- Loss function tuning
- Ensemble methods

## ğŸ” Model Selection Guide

### High Accuracy Priority
```
DeepLab v3+ > PSPNet > U-Net > SegNet
```
- Choose DeepLab v3+ vá»›i ResNet101 backbone
- Use large image size (512+)
- Train for 100+ epochs

### Speed Priority  
```
SegNet > U-Net > PSPNet > DeepLab v3+
```
- Choose U-Net vá»›i lightweight encoder
- Use smaller image size (256)
- Consider mobile-optimized variants

### Balanced Performance
```
U-Net (pretrained) > PSPNet > DeepLab v3+ (light) > SegNet
```
- U-Net vá»›i ResNet34 encoder
- Image size 256-384
- 50 epochs training

## ğŸ¤ Contributing

### Development Setup
```bash
# Clone vÃ  setup development environment
git clone <repository-url>
cd phan_vung
pip install -r requirements.txt

# Run tests
python -m pytest tests/

# Format code
black .
isort .
```

### Adding New Models
1. Create model file trong `models/`
2. Add factory function
3. Update training script
4. Add tests vÃ  documentation

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **PyTorch team** cho excellent deep learning framework
- **Segmentation Models PyTorch** cho pretrained models
- **PASCAL VOC** vÃ  **Cityscapes** teams cho datasets
- Research community cho open-source implementations

## ğŸ“ Contact & Support

- **Issues**: Report bugs hoáº·c feature requests via GitHub Issues
- **Discussions**: Technical questions via GitHub Discussions  
- **Email**: [your.email@example.com] cho business inquiries

---

**â­ Náº¿u project nÃ y há»¯u Ã­ch, hÃ£y star repository!**

## ğŸ“š Citation

Náº¿u báº¡n sá»­ dá»¥ng code nÃ y trong research, please cite:

```bibtex
@misc{semantic_segmentation_2024,
  title={Semantic Segmentation: A Comprehensive Study and Implementation},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/phan_vung}
}
``` 